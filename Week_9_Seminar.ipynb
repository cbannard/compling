{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"Week_9_Seminar.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4_7KjskLX1q-"},"source":["# LELA32051 Computational Linguistics Week 9\n","\n","This week we are going to take a look at part of speech tagging"],"id":"4_7KjskLX1q-"},{"cell_type":"markdown","metadata":{"id":"WcTkkt4bX1rB"},"source":["## Tagged corpora\n","In looking to understand part of speech tagging, it is useful to start by looking at some human (rather than machine) tagged data. NLTK contains a number of corpora. We can import a few of these as follows:"],"id":"WcTkkt4bX1rB"},{"cell_type":"code","metadata":{"id":"vhYuBQkZX1rB"},"source":["import nltk\n","nltk.download('brown')\n","from nltk.corpus import brown\n","nltk.download('sinica_treebank')\n","nltk.download('indian')\n","nltk.download('mac_morpho')\n","nltk.download('cess_cat')\n","nltk.download('conll2002')"],"id":"vhYuBQkZX1rB","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8FhvPh-X7Lo"},"source":["brown.tagged_words()"],"id":"B8FhvPh-X7Lo","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBsMpgZXYWZ1"},"source":["nltk.download('universal_tagset')"],"id":"qBsMpgZXYWZ1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2p4sTYzbYYMu"},"source":["brown.tagged_words(tagset=\"universal\")"],"id":"2p4sTYzbYYMu","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fOKYUStX1rD"},"source":["nltk.corpus.sinica_treebank.tagged_words() # Chinese"],"id":"9fOKYUStX1rD","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rL4gHKSX1rD"},"source":["nltk.corpus.indian.tagged_words() # Hindi\n"],"id":"5rL4gHKSX1rD","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NaRGvUuX1rE"},"source":["nltk.corpus.mac_morpho.tagged_words() #Spanish\n"],"id":"-NaRGvUuX1rE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOXUk5uPX1rE"},"source":["nltk.corpus.conll2002.tagged_words() # Dutch"],"id":"VOXUk5uPX1rE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHBp369FX1rF"},"source":["nltk.corpus.cess_cat.tagged_words() # Catalan"],"id":"yHBp369FX1rF","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aMf3v1A0X1rI"},"source":["## A couple more bits of basic Python (the last of the semester)"],"id":"aMf3v1A0X1rI"},{"cell_type":"markdown","metadata":{"id":"IgKtjA4AX1rI"},"source":["### List comprehension\n","\n","List comprehension is a useful tool in Python for making lists. Here we will use them as an efficient way to form lists from other data structures via for loops."],"id":"IgKtjA4AX1rI"},{"cell_type":"markdown","metadata":{"id":"91Ib2BR3X1rJ"},"source":["We saw earlier in the semester that we could use for loops to iterate over a list (e.g. a sentence) in order to apply some function to its elements.  For example:"],"id":"91Ib2BR3X1rJ"},{"cell_type":"code","metadata":{"id":"_ZeNXmg3nGNQ"},"source":["brown.sents()"],"id":"_ZeNXmg3nGNQ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3rl3bEFX1rJ"},"source":["sent_pretty = []\n","for sent in brown.sents():\n","     sent_pretty.append((\" \".join(sent)))"],"id":"J3rl3bEFX1rJ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YVth6FRnOUs"},"source":["print(sent_pretty[1:2])"],"id":"3YVth6FRnOUs","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"872hiTAWX1rJ"},"source":["List comprehension allows us to do that in a single line. For example:"],"id":"872hiTAWX1rJ"},{"cell_type":"code","metadata":{"id":"S0iiT1COmatS"},"source":["sent_pretty = [\" \".join(sent) for sent in brown.sents()]"],"id":"S0iiT1COmatS","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wD1irpLjnSNR"},"source":["print(sent_pretty[1:2])"],"id":"wD1irpLjnSNR","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zu4T6ySfX1rJ"},"source":["### Dictionaries\n","\n","A data structure that we are making use of here that is very useful in Python is the Dictionary. This a structure that allows you to store a look up associations between \"key\" and \"values\".\n","\n","An empty dictionary is created by writing"],"id":"zu4T6ySfX1rJ"},{"cell_type":"code","metadata":{"id":"1kKw3skQX1rJ"},"source":["pos = {}"],"id":"1kKw3skQX1rJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbcH4rKmX1rK"},"source":["You can then add entries to it as follows:"],"id":"lbcH4rKmX1rK"},{"cell_type":"code","metadata":{"id":"gnvIL4s4X1rK"},"source":["pos['colourless'] = 'ADJ'\n","pos['ideas'] = 'NOUN'"],"id":"gnvIL4s4X1rK","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MWqsgAJEncJ7"},"source":["The full dictionary can be viewed as follows:"],"id":"MWqsgAJEncJ7"},{"cell_type":"code","metadata":{"id":"zimxoszOnen5"},"source":["print(pos)"],"id":"zimxoszOnen5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0v0dxdWX1rK"},"source":["And you can look up entries by key as follows:"],"id":"d0v0dxdWX1rK"},{"cell_type":"code","metadata":{"id":"OTECj6PIX1rK"},"source":["pos['colourless']"],"id":"OTECj6PIX1rK","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1crx5JSnv7i"},"source":["And you can loop over the key and value separately "],"id":"m1crx5JSnv7i"},{"cell_type":"code","metadata":{"id":"mgUAQigxX1rK"},"source":["for key, val in sorted(pos.items()): \n","     print(key + \":\", val)"],"id":"mgUAQigxX1rK","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sS4HRV5PaJ7p"},"source":["## Inspecting tagged corpora\n","\n","Inspecting human tagged corpora can be useful for both linguistic research and for building taggers.\n","\n","To give a few examples:"],"id":"sS4HRV5PaJ7p"},{"cell_type":"markdown","metadata":{"id":"p9MY9J0JO8ZU"},"source":["Most straightforwardly you can look at the frequency with which particular words are given a tag (we will return to this later when we come to build a tagger)."],"id":"p9MY9J0JO8ZU"},{"cell_type":"code","metadata":{"id":"3reX-cyOO8ZU"},"source":["brown_tagged = brown.tagged_words(tagset='universal')\n","cfd1 = nltk.ConditionalFreqDist(brown_tagged)\n","cfd1['walk']"],"id":"3reX-cyOO8ZU","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nm_xk9KlO8ZU"},"source":["You can look at which words are most common for a given part of speech tag."],"id":"Nm_xk9KlO8ZU"},{"cell_type":"code","metadata":{"id":"iiJyruP-X1rH"},"source":["brown_tagged = brown.tagged_words(tagset='universal')\n","word_tag_fd = nltk.FreqDist(brown_tagged)\n","[(wt[0],_) for (wt, _) in word_tag_fd.most_common() if wt[1] == 'VERB']"],"id":"iiJyruP-X1rH","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LgPMnoS7O8ZV"},"source":["You can look at the frequency with which particular word classes precede particular words"],"id":"LgPMnoS7O8ZV"},{"cell_type":"code","metadata":{"id":"qOYrY5lbX1rF"},"source":["brown_tagged = brown.tagged_words(tagset='universal')\n","tags = [b[1] for (a, b) in nltk.bigrams(brown_tagged) if a[0] == 'often']\n","fd = nltk.FreqDist(tags)\n","fd.tabulate()"],"id":"qOYrY5lbX1rF","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPvjkxfDX1rH"},"source":["Or you can look at the frequency with which particular word classes precede other word classes:"],"id":"UPvjkxfDX1rH"},{"cell_type":"code","metadata":{"id":"8xvG9WOAX1rH"},"source":["brown_tagged = brown.tagged_words(tagset='universal')\n","word_tag_pairs = nltk.bigrams(brown_tagged)\n","noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n","noun_preceders_fd = nltk.FreqDist(noun_preceders)\n","[(wt,_) for (wt, _) in noun_preceders_fd.most_common()]"],"id":"8xvG9WOAX1rH","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XdK3VjNO8ZW"},"source":["And you can search for particular constructional patterns"],"id":"6XdK3VjNO8ZW"},{"cell_type":"code","metadata":{"id":"ulo7vBehX1rI"},"source":["for tagged_sent in brown.tagged_sents(categories=\"news\"):\n","    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(tagged_sent):\n","        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\n","            print(w1, w2, w3)"],"id":"ulo7vBehX1rI","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6ib7GseX1rK"},"source":["## Building a tagger"],"id":"r6ib7GseX1rK"},{"cell_type":"markdown","metadata":{"id":"aVqeMRw0O8ZW"},"source":["In week three we looked at vector space models and saw that just by looking at the words that surround other words we can group them together into something like word classes:"],"id":"aVqeMRw0O8ZW"},{"cell_type":"code","metadata":{"id":"zBlQ6-gFO8ZW"},"source":["text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n","text.similar('car')\n","text.similar('the')"],"id":"zBlQ6-gFO8ZW","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzA8ISaKO8ZW"},"source":["However this doesn't give great performance, and it is more common to build taggers by taking human-tagged data and learning to classify words by using the words and tags as training data."],"id":"gzA8ISaKO8ZW"},{"cell_type":"markdown","metadata":{"id":"d3XT2SiLO8ZW"},"source":["A very simple approach that actually works quite well is to find the most common tag for each word in a training corpus (as we did above) and just tag all occurences of each word with its most common tag:"],"id":"d3XT2SiLO8ZW"},{"cell_type":"code","metadata":{"id":"RhEZn32bX1rL"},"source":["brown_tagged_sents = brown.tagged_sents(tagset='universal')"],"id":"RhEZn32bX1rL","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kVAmnCIX1rM"},"source":["unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)"],"id":"5kVAmnCIX1rM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mF1KCV3gX1rM"},"source":["unigram_tagger.tag([\"the\",\"cat\",\"sat\",\"on\",\"the\",\"mat\"])"],"id":"mF1KCV3gX1rM","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guYS2yoPO8ZX"},"source":["We can formally evaluate this by splitting our data into a training set and a testing set. We obtain the by-word tag frequencies from the training set and evaluate by tagging the test set and comparing our predicted tags to the human tags."],"id":"guYS2yoPO8ZX"},{"cell_type":"code","metadata":{"id":"Fezj3MKPX1rM"},"source":["training_set_size = int(len(brown_tagged_sents) * 0.9)\n","train_sents = brown_tagged_sents[:training_set_size]\n","test_sents = brown_tagged_sents[training_set_size:]\n","unigram_tagger = nltk.UnigramTagger(train_sents)\n","unigram_tagger.evaluate(test_sents)"],"id":"Fezj3MKPX1rM","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ft2V8G1DO8ZX"},"source":["We want to improve this, and an obvious next step is to give the tag that is most frequent for this word when it follows the previous word. The problem is this doesn't do very well. Any idea why?"],"id":"ft2V8G1DO8ZX"},{"cell_type":"code","metadata":{"id":"vpyhojpNX1rM"},"source":["bigram_tagger = nltk.BigramTagger(train_sents)"],"id":"vpyhojpNX1rM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4PK9DIBX1rN"},"source":["bigram_tagger.evaluate(test_sents)"],"id":"_4PK9DIBX1rN","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ThUxUTrqO8ZY"},"source":["We can still make use of the bigram information by combining it with the unigram tagger via a process known as backing off - for each word we check whether we have seen that word and preceding word in our training data. If we have then we tag it with the most frequent tag for that word in that context. If we haven't seen it then we tag the word with its most frequent tag regardless of context. And if we haven't seen the word before we tag it as a noun."],"id":"ThUxUTrqO8ZY"},{"cell_type":"code","metadata":{"id":"QRIRmxiIX1rN"},"source":["t0 = nltk.DefaultTagger('NOUN')\n","t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n","t2 = nltk.BigramTagger(train_sents, backoff=t1)\n","t2.evaluate(test_sents)"],"id":"QRIRmxiIX1rN","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aulYA40rX1rL"},"source":["### Regular expression based tagging\n","\n","As a next step we want to use a more intelligent way to deal with words we haven't seen before, but making use of their orthography and/or morphology. Write regular expressions to classify words in this way and see if you can improve performance. I've added one example rule to get you started."],"id":"aulYA40rX1rL"},{"cell_type":"code","metadata":{"id":"V-xWlo8jX1rL"},"source":["patterns = [\n","    (r'.*ing$', 'VERB')\n","      ]"],"id":"V-xWlo8jX1rL","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HL5p4DXGX1rN"},"source":["t0 = nltk.DefaultTagger('NOUN')\n","t1 = nltk.RegexpTagger(patterns, backoff=t0)\n","t2 = nltk.UnigramTagger(train_sents, backoff=t1)\n","t3 = nltk.BigramTagger(train_sents, backoff=t2)\n","t3.evaluate(test_sents)"],"id":"HL5p4DXGX1rN","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XW49NJtgO8ZZ"},"source":["As with other classification tasks we can generate a confusion matrix to see where things are going right or wrong."],"id":"XW49NJtgO8ZZ"},{"cell_type":"code","metadata":{"id":"SXMlkijYX1rN"},"source":["from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","predicted = [tag for sent in brown.sents(categories='editorial') for (word, tag) in t3.tag(sent)]\n","true = [tag for (word, tag) in brown.tagged_words(categories='editorial',tagset=\"universal\")]\n","print(pd.DataFrame(confusion_matrix(predicted, true),index=set(predicted)))         "],"id":"SXMlkijYX1rN","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99NYaf-rX1rN"},"source":["### NLTK's Averaged Perceptron tagger\n","\n","NLTKs default prebuilt tagger uses a Perceptron just like that we have been using for other tasks on the module. For more information on this approach see here: https://explosion.ai/blog/part-of-speech-pos-tagger-in-python\n"],"id":"99NYaf-rX1rN"},{"cell_type":"code","metadata":{"id":"cARyYZbeumrs"},"source":["nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"id":"cARyYZbeumrs","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l0ivT2SRurCm"},"source":["It can be run straightforwardly like this:"],"id":"l0ivT2SRurCm"},{"cell_type":"code","metadata":{"id":"fAZY4tcwX1rN"},"source":["text = nltk.word_tokenize(\"And now for something completely different\")\n","nltk.pos_tag(text, tagset=\"universal\")"],"id":"fAZY4tcwX1rN","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXR-hDjnX1rN"},"source":["### POS tagging in other languages\n","\n","POS taggers are available for a great many languages. A popular package called Spacy contains a number. Here, as an example, is a German tagger."],"id":"gXR-hDjnX1rN"},{"cell_type":"markdown","metadata":{"id":"8qgsamK6X1rN"},"source":["#### German"],"id":"8qgsamK6X1rN"},{"cell_type":"code","metadata":{"id":"sR6hNMiiX1rO"},"source":["!python -m spacy download de_core_news_sm"],"id":"sR6hNMiiX1rO","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAAtX7qNX1rO"},"source":["nlp = spacy.load('de_core_news_sm')"],"id":"vAAtX7qNX1rO","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jQcjD8PX1rO"},"source":["s1_t = nlp(s3)"],"id":"7jQcjD8PX1rO","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QuC66AL2X1rO"},"source":["for tk in s1_t:\n","    print(tk.text, tk.tag_, tk.pos_)"],"id":"QuC66AL2X1rO","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqQ6hQEziFSp"},"source":["### Chunking / Shallow Parsing\n","\n","Chunking involves grouping together words into elementary phrases. In its most common form it doesn't involve any hierachical structure.\n"],"id":"yqQ6hQEziFSp"},{"cell_type":"code","metadata":{"id":"iU7Nm8nxWtP3"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('universal_tagset')"],"id":"iU7Nm8nxWtP3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvmAzVJnh4It"},"source":["text = nltk.word_tokenize(\"I study Linguistics and Social Anthropology at the University of Manchester\")"],"id":"PvmAzVJnh4It","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zDIdnUEWIFJ"},"source":["grammar = r\"\"\"\n","  NP: {<DET|ADP>?<ADJ>*<NOUN>}\n","      {<NOUN>+} \n","\"\"\"\n","sent=nltk.pos_tag(text,tagset=\"universal\")\n","cp = nltk.RegexpParser(grammar)\n","cs = cp.parse(sent)\n","print(cs)"],"id":"5zDIdnUEWIFJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e53dKlaEg73e"},"source":["Update the grammar so that it produces the following shallow parse: <br> <br>\n","(S <br>\n","  (NP I/PRON) <br>\n","  study/VERB <br>\n","  (NP Linguistics/NOUN and/CONJ Social/NOUN Anthropology/NOUN) <br>\n","  at/ADP <br>\n","  the/DET <br>\n","  (NP University/NOUN of/ADP Manchester/NOUN)) <br>"],"id":"e53dKlaEg73e"},{"cell_type":"markdown","metadata":{"id":"MmMIKn0HWJwv"},"source":["### Named Entity Recognition\n","\n","NLTK also has an inbuilt named entity recognition tool. "],"id":"MmMIKn0HWJwv"},{"cell_type":"code","metadata":{"id":"ykpXHBu7kb1X"},"source":["nltk.download('words')\n","nltk.download('maxent_ne_chunker')"],"id":"ykpXHBu7kb1X","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1mHPnO1YF3J"},"source":["sent=nltk.pos_tag(text,tagset=\"universal\")\n","print(nltk.ne_chunk(sent))"],"id":"r1mHPnO1YF3J","execution_count":null,"outputs":[]}]}