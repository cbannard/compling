{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada7675f",
   "metadata": {},
   "source": [
    "# LELA32051 Computational Linguistics Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c58486",
   "metadata": {},
   "source": [
    "## Tokenisation and Morphology\n",
    "\n",
    "In this week's session we are going to look at how to implement the various preprocessing tasks introduced in the lecture. In doing so we are going to make use of regular expressions, so I will start by introducing these.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a659d6d",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6fcae",
   "metadata": {},
   "source": [
    "Last week we used functions that belong to the datatype string to manipulate text. This week we are going to explore a much more powerful way of manipulating text - the regular expression. In order to do this we need to import the regular expressions library (https://docs.python.org/3/library/re.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0aad8",
   "metadata": {},
   "source": [
    "In order to explore this we will import text again and tokenise it in the same way we did last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using colab\n",
    "from google.colab import files\n",
    "files.upload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d285d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('2554-0.txt')\n",
    "raw = f.read()\n",
    "chapter_one = raw[5464:23725]\n",
    "chapter_one = chapter_one.replace(\".\",\" .\")\n",
    "chapter_one_tokens = str.split(chapter_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a9432-87c1-4ddf-9f55-b50c88500410",
   "metadata": {},
   "source": [
    "### re.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea0e59",
   "metadata": {},
   "source": [
    "There are a few functions in the re library that we will need to learn about. One of these is re.search - this searches for occurence of a pattern in a given string. It takes a regular expression to search for, between quotes, as its first argument and a string to search as its second argument. It returns a boolean value of true (actually a match object with a boolean value of true but we can ignore that nuance) if it finds an occurence of the pattern. We can use it to search through a list of tokens and print out tokens that match a target pattern using a for loop and an if statement as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a24651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    if re.search(\"ed\", w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab04e1-81ce-44cb-93d6-b7a9ae13d7a9",
   "metadata": {},
   "source": [
    "Before considering other functions we will use search to try out a couple of aspects of regular expressions we learned about in this week's lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a3b40-d007-4fcc-987b-9672ba809d62",
   "metadata": {},
   "source": [
    "Activity: Alter the regular expression so that it will detect sequences that contain ed or er (note: there are at least 2 ways to do this using methods covered in the lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec19b76-62ac-4626-a7bc-5320ce600d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee53232c-8821-4893-8f7f-44541fbed2eb",
   "metadata": {},
   "source": [
    "Activity: Alter the regular expression so that it will detect any single character followed by the letter \"d\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c00ee9-ca07-486e-9183-7886ea555155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae61ef4-4fbc-4df2-80ac-a890d33823b0",
   "metadata": {},
   "source": [
    "Activity: Alter the regular expression so that it will detect any sequence of one of more character followed by the letter \"d\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4d305-d779-489c-92b1-77b78bb08e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f451186-a838-45c4-b5b5-239e65f8c917",
   "metadata": {},
   "source": [
    "Activity: Alter the regular expression so that it will detect any string that contains any letter other than \"e\" followed by \"d\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feff6eb-4d0b-42c0-b3e6-a5b5f54d1958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99c3dc1f-4e63-450c-a54c-04bb9c498254",
   "metadata": {},
   "source": [
    "This brings us to the first technique that wasn't covered in the lecture. A dollar sign marks the end of the string being searched, so if we put it at the end of our pattern it will only find patterns that occur at the end of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632e410-0a7c-4500-9dc3-9191c20ad08b",
   "metadata": {},
   "source": [
    "Activity: update the loop below so that it only matches tokens that end in \"er\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d654f7-1324-491f-a562-c5aa6f9b6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    if re.search(\"er\", w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab42c9-7c82-4a21-8944-c53d4193106e",
   "metadata": {},
   "source": [
    "A carat symbol marks the beginning of a string so can be used to make sure the pattern is only matched when it occurs at the beginning of the string being searched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad492a-d68b-44e3-9be6-6b154088d067",
   "metadata": {},
   "source": [
    "Activity: Create a loop below so that it matches any tokens that begin with b or B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c43e2e-a9b8-4f90-b73f-180f806df95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ff4570-055b-4137-87d9-55c3d65bcee8",
   "metadata": {},
   "source": [
    "Activity: Combine what you have done above with a method we looked at last week in order to count the number of occurences of sequences that end in \"ed\" in chapter one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91425803-2b67-4437-98ce-115d0246ab49",
   "metadata": {},
   "source": [
    "### re.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9d026-d5fb-4a22-adb1-8c2023d1b757",
   "metadata": {},
   "source": [
    "re.match is similar to re.search except that it only finds strings that start with the pattern searched for, while search finds it anywhere in the string unless otherwise specified (with ^ or $)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2f856-79f3-491c-92ee-1483d30e1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    if re.match(\"er\", w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d69e77-ca73-40e8-94ca-5ff1b5b65d2b",
   "metadata": {},
   "source": [
    "### re.findall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075081ea-11b2-4ecb-81fc-87f38fce17b0",
   "metadata": {},
   "source": [
    "Another useful function is re.findall. This searches for patterns and returns all substrings that are matched by the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    print(re.findall(\"ed\", w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f86d63-f6f9-4e46-8401-c48f2641f0c0",
   "metadata": {},
   "source": [
    "Activity: How would we change the regular expression to get it to return the whole token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e552f38-ef36-4ebb-a664-5157459c9cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc7c486-e16a-4292-8be8-de6368fdc0d1",
   "metadata": {},
   "source": [
    "If we want to make sure that it is the whole token being matched we can use the function re.fullmatch(). This returns none if the regular expression doesn't match the whole string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3884f-ca83-4914-87cc-c59784a51e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    if re.fullmatch(\"ed\", w):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e9792-1b77-4165-a9c5-dc0f5706df1b",
   "metadata": {},
   "source": [
    "re.findall will return ALL patterns in a string so we can actually run it on non-tokenised text and dispense with the for loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4ec-5342-4410-800f-a49beb326aa4",
   "metadata": {},
   "source": [
    "Activity: Why does the following fail and how can we change it so that it finds all occurences of \"ed\" in the string chapter_one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eb7071bc-ae27-409d-a971-aaa06dedcf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(\"ed$\", chapter_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbec9a-3371-4caf-b8a0-40412a295767",
   "metadata": {},
   "source": [
    "Activity: and how can we change it so that it finds all words containing \"ed\" (rather than just the substring \"ed\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4975e9-b5f8-4481-b2c9-b80e5514c8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd639fea-ee32-420b-9dc9-3eeebaf760d8",
   "metadata": {},
   "source": [
    "New function: len() is a built-in Python function that tells use the length of various data types and structures including strings and lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00965e09-5ce8-4d85-aaff-1aca7109ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chapter_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f1d30-c54e-4cb6-9020-95c087ee6d93",
   "metadata": {},
   "source": [
    "Activity: Use the len function together with findall in order to count occurences of the sequence \"ed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f6987-d22a-48ff-b837-dee4153cca27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad4f2df-d489-4629-ad67-42e47f1a1bfb",
   "metadata": {},
   "source": [
    "Advanced activity: Use the len function together with findall in order to count occurences of words that end in \"ed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da41e2-4214-4bb1-af18-cf0e2a48e6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559c5b61-2875-4c5e-805e-064b0e7311bb",
   "metadata": {},
   "source": [
    "### re.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610cb9f-f6ea-4ab3-8ad9-59c225502a84",
   "metadata": {},
   "source": [
    "For patterns that we want to use again and again we can use the function re.compile(). This returns a re \"object\" that has all of the re functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a557eb5-5b56-4f90-9fde-f65e8e30200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_tense = re.compile(\"ed\")\n",
    "print(past_tense.findall(chapter_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d8356-c163-4392-bfaf-97630b7497fe",
   "metadata": {},
   "source": [
    "### re.sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3dabf-a023-49f5-90fb-8709d218f78e",
   "metadata": {},
   "source": [
    "Another very useful function is re.sub. This finds all occurences of a given sequence and replaces it with a sequence provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b85ce6-e8cd-4eb3-904b-42c47c28a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub('ed','ing',chapter_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9dfd45-d384-4e6e-ace8-56b54da6462e",
   "metadata": {},
   "source": [
    "Activity: Write a regular expression or series of regular expression to translate the first sentence of chapter_one from past to present tense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0974f6-9a71-48fb-9b7d-e8d6b70ab3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_sentences = chapter_one[0:175]\n",
    "print(opening_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cbb25-55f3-4f56-843a-7695409575db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1dbb833-d727-4406-b841-00f593e0a7e7",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d91273-4d07-444b-b80b-9e1ab940241d",
   "metadata": {},
   "source": [
    "Grouping is a very powerful technique for picking out substrings from a string that matches a specified pattern. It is done using parentheses. The function groups() can be used to get a list of the substrings (technically a tuple which is like a list but immutable meaning that the element cannot be changed once created) from match objects (which are returned by match() and search()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5df1d-4e8b-4ac8-ac35-e2dfdd2bcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in chapter_one_tokens:\n",
    "    m = re.search(\"(B)(.*)\", w)\n",
    "    if m:\n",
    "        print(m.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237b7bd-9aa6-445a-b8da-4f965c52a360",
   "metadata": {},
   "source": [
    "Grouping can also be done with re.findall, which returns a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a71b8-0d7e-4ece-99a2-5eace6b15e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"(B)(.*)\", chapter_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc275e3-c9b3-4bf9-9a1a-8a58d9f42b44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a2a53eb-c5c4-429e-8d73-21d7ff1e2cbe",
   "metadata": {},
   "source": [
    "### Combining sub with groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c0c473-2545-415d-8bb1-e27821356e82",
   "metadata": {},
   "source": [
    "The re.sub function and grouping become particularly powerful when they are combined. You can use parentheses to capture a particular substring within a pattern and then use it in your replacement string within sub. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf039b0-73da-496b-9b3e-a686ced9a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub('([a-z]+)ed','\\\\1ing',chapter_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2c1c7-993d-4338-97dd-d3c33c49cc4f",
   "metadata": {},
   "source": [
    "### re.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba8578-45c9-498d-be68-5c6dc4af2c18",
   "metadata": {},
   "source": [
    "re.split() takes a regular expression as a first argument (unless you have a precompiled pattern) and a string as second argument, and split the string into tokens divided by all substrings matched by the regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924581e-f6a3-4aee-85f2-b057d521e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split_on = re.compile(\" \")\n",
    "chapter_one_tokens_new = to_split_on.split(chapter_one)\n",
    "print(chapter_one_tokens_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397d1df-cb85-45b0-b02d-3eda67c2863c",
   "metadata": {},
   "source": [
    "### Escaping special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e158957-aa5e-497b-837e-bc42a74f263f",
   "metadata": {},
   "source": [
    "We have learned about a number of character that have a special meaning in regular expressions (periods, dollar signs etc). We might sometimes want to search for these characters in strings. To do this we can \"escape\" the character using a backslash(\\) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56db94-2465-462b-a01a-0d1d18918c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\.\",chapter_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67651269-ac9b-4956-bcbe-20f54e705108",
   "metadata": {},
   "source": [
    "## Putting it all together "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f56205-c74b-430c-b9b1-a4f362698ad1",
   "metadata": {},
   "source": [
    "Activity: Can we use the functions and techniques we have learned about so far in order to build a functioning tokenizer?\n",
    "\n",
    "First let's reload the chapter as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a9ec8-0c2d-4b6a-a3fb-0daad1ec7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('2554-0.txt')\n",
    "raw = f.read()\n",
    "chapter_one = raw[5464:23725]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8971495-514e-4c75-87a1-d2cc4ad0ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split_on = re.compile(\" \")\n",
    "chapter_one_tokens_new = to_split_on.split(chapter_one)\n",
    "print(chapter_one_tokens_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e6896-0712-491e-9343-518b186cb3b2",
   "metadata": {},
   "source": [
    "Activity: Can we use the functions and techniques we have learned about so far in order to build a functioning sentence segmenter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946d476-6fdd-46e4-937c-2cbef76ab5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06cf589-4bd6-4803-96cf-ed86a34d5011",
   "metadata": {},
   "source": [
    "Activity: Can we use the functions and techniques we have learned about so far in order to build a functioning lemmatizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58086b07-69d9-4f58-ae04-acb2d5587255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab6c546-7b79-4f4d-8c70-ce361255fbd9",
   "metadata": {},
   "source": [
    "## Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380e17a",
   "metadata": {},
   "source": [
    "So far we have looking at the core Python programming language and the re library. However much of the time this semester we will be making use of even more  powerful libraries for natural language processing and machine learning. Today I want to introduce the first of these - \"Natural Language Toolkit\" or nltk.\n",
    "\n",
    "The first thing we need to do is to make sure we have the libraries we want installed. On Google Colab they are all already there. If your are using your own machine you will have to install it using the following command (unlike for re which is present by default and just needs to be loaded).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk # If using anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab644be",
   "metadata": {},
   "source": [
    "In order to use the library we then need to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07639361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28b620",
   "metadata": {},
   "source": [
    "### Tokenising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('2554-0.txt')\n",
    "raw = f.read()\n",
    "chapter_one = raw[5464:23725]\n",
    "print(chapter_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_one_tokens = nltk.word_tokenize(chapter_one)\n",
    "print(chapter_one_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2fb31-aa51-4934-bd12-0cb8973d4c23",
   "metadata": {},
   "source": [
    "### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b644fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_one_sentences = nltk.sent_tokenize(' '.join(chapter_one_tokens))\n",
    "print(chapter_one_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d92df-d481-45e4-a1e3-6d4543de4586",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b84f1-608a-4911-ba4e-9b1972af43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "for t in chapter_one_tokens:\n",
    "    print(porter.stem(t),end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526b3c5-d4c3-40fb-891c-b36935baf5e3",
   "metadata": {},
   "source": [
    "### Lemmatising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd979cf-a661-4288-91ca-70deb443e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "for t in chapter_one_tokens:\n",
    "    print(wnl.lemmatize(t),end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
